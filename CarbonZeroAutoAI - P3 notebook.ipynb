{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "![image](https://github.com/IBM/watson-machine-learning-samples/raw/master/cloud/notebooks/headers/AutoAI-Banner_Pipeline-Notebook.png)\n# Pipeline 3 Notebook - AutoAI Notebook v1.15.8\n\nConsider these tips for working with an auto-generated notebook:\n- Notebook code generated using AutoAI will execute successfully. If you modify the notebook, we cannot guarantee it will run successfully.\n- This pipeline is optimized for the original data set. The pipeline might fail or produce sub-optimum results if used with different data.  If you want to use a different data set, consider retraining the AutoAI experiment to generate a new pipeline. For more information, see <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/autoai-notebook.html\">Cloud Platform</a>. \n- Before modifying the pipeline or trying to re-fit the pipeline, consider that the code converts dataframes to numpy arrays before fitting the pipeline (a current restriction of the preprocessor pipeline).\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"content\"></a>\n## Notebook content\n\nThis notebook contains a Scikit-learn representation of AutoAI pipeline. This notebook introduces commands for getting data, training the model, and testing the model. \n\nSome familiarity with Python is helpful. This notebook uses Python 3.8 and scikit-learn 0.23.2."
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": "## Notebook goals\n\n-  Scikit-learn pipeline definition\n-  Pipeline training \n-  Pipeline evaluation\n\n## Contents\n\nThis notebook contains the following parts:\n\n**[Setup](#setup)**<br>\n&nbsp;&nbsp;[Package installation](#install)<br>\n&nbsp;&nbsp;[AutoAI experiment metadata](#variables_definition)<br>\n&nbsp;&nbsp;[Watson Machine Learning connection](#connection)<br>\n**[Pipeline inspection](#inspection)** <br>\n&nbsp;&nbsp;[Read training data](#read)<br>\n&nbsp;&nbsp;[Train and test data split](#split)<br>\n&nbsp;&nbsp;[Make pipeline](#preview_model_to_python_code)<br>\n&nbsp;&nbsp;[Train pipeline model](#train)<br>\n&nbsp;&nbsp;[Test pipeline model](#test_model)<br>\n**[Next steps](#next_steps)**<br>\n**[Copyrights](#copyrights)**"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"setup\"></a>\n# Setup"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"install\"></a>\n## Package installation\nBefore you use the sample code in this notebook, install the following packages:\n - ibm_watson_machine_learning,\n - autoai-libs,\n - scikit-learn,\n - xgboost.\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:00:45.009458Z",
                    "iopub.status.busy": "2020-10-12T14:00:45.007968Z",
                    "iopub.status.idle": "2020-10-12T14:00:46.037702Z",
                    "shell.execute_reply": "2020-10-12T14:00:46.038270Z"
                },
                "pycharm": {
                    "name": "#%%\n"
                },
                "scrolled": true
            },
            "outputs": [],
            "source": "!pip install ibm-watson-machine-learning | tail -n 1\n!pip install -U autoai-libs==1.12.15 | tail -n 1\n!pip install -U scikit-learn==0.23.2 | tail -n 1\n!pip install -U xgboost==1.3.3 | tail -n 1"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"variables_definition\"></a>\n## AutoAI experiment metadata\nThe following cell contains the training data connection details.  \n**Note**: The connection might contain authorization credentials, so be careful when sharing the notebook."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:00:49.797633Z",
                    "iopub.status.busy": "2020-10-12T14:00:49.796778Z",
                    "iopub.status.idle": "2020-10-12T14:00:57.182715Z",
                    "shell.execute_reply": "2020-10-12T14:00:57.183132Z"
                },
                "pycharm": {
                    "is_executing": true
                }
            },
            "outputs": [],
            "source": "from ibm_watson_machine_learning.helpers import DataConnection\nfrom ibm_watson_machine_learning.helpers import ContainerLocation\n\ntraining_data_reference = [\n    DataConnection(\n        data_asset_id='c3fd3bd5-2e6b-4c6f-b854-b17c02f0b225'\n    ),\n]\ntraining_result_reference = DataConnection(\n    location=ContainerLocation(\n        path='auto_ml/a837d600-f66c-4608-9fb4-0210c486124b/wml_data/921c8707-2c39-4104-9625-afb1bf958c0e/data/automl',\n        model_location='auto_ml/a837d600-f66c-4608-9fb4-0210c486124b/wml_data/921c8707-2c39-4104-9625-afb1bf958c0e/data/automl/model.zip',\n        training_status='auto_ml/a837d600-f66c-4608-9fb4-0210c486124b/wml_data/921c8707-2c39-4104-9625-afb1bf958c0e/training-status.json'\n    )\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "Following cell contains input parameters provided to run the AutoAI experiment in Watson Studio."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:00:57.187305Z",
                    "iopub.status.busy": "2020-10-12T14:00:57.186602Z",
                    "iopub.status.idle": "2020-10-12T14:00:57.188392Z",
                    "shell.execute_reply": "2020-10-12T14:00:57.188878Z"
                },
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "experiment_metadata = dict(\n    prediction_type='binary',\n    prediction_column='Reduction',\n    holdout_size=0.1,\n    scoring='accuracy',\n    csv_separator=',',\n    random_state=33,\n    max_number_of_estimators=2,\n    training_data_reference=training_data_reference,\n    training_result_reference=training_result_reference,\n    deployment_url='https://us-south.ml.cloud.ibm.com',\n    project_id='47b1306b-aea1-4cd3-a791-afbc3f47b41d',\n    positive_label='TRUE',\n    drop_duplicates=False\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"connection\"></a>\n## Watson Machine Learning connection\n\nThis cell defines the credentials required to work with the Watson Machine Learning service.\n\n**Action:** Please provide IBM Cloud apikey following [docs](https://cloud.ibm.com/docs/account?topic=account-userapikey)."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "api_key = 'PUT_YOUR_APIKEY_HERE'"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "wml_credentials = {\n    \"apikey\": api_key,\n    \"url\": experiment_metadata['deployment_url']\n}"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "from ibm_watson_machine_learning import APIClient\n\nwml_client = APIClient(wml_credentials)\n\nif 'space_id' in experiment_metadata:\n    wml_client.set.default_space(experiment_metadata['space_id'])\nelse:\n    wml_client.set.default_project(experiment_metadata['project_id'])\n    \ntraining_data_reference[0]._wml_client = wml_client"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"inspection\"></a>\n# Pipeline inspection"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": "<a id=\"read\"></a>\n## Read training data\n\nRetrieve training dataset from AutoAI experiment as pandas DataFrame.\n\n**Note**: If reading data results in an error, provide data as Pandas DataFrame object, for example, reading .CSV file with `pandas.read_csv()`"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:01:16.076169Z",
                    "iopub.status.busy": "2020-10-12T14:01:16.075589Z",
                    "iopub.status.idle": "2020-10-12T14:01:19.190233Z",
                    "shell.execute_reply": "2020-10-12T14:01:19.190807Z"
                },
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "train_X, test_X, train_y, test_y = training_data_reference[0].read(experiment_metadata=experiment_metadata, with_holdout_split=True)"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": "<a id=\"preview_model_to_python_code\"></a>\n## Make pipeline\nIn the next cell, you can find the Scikit-learn definition of the selected AutoAI pipeline."
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": "#### Import statements."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "from autoai_libs.transformers.exportable import NumpyColumnSelector\nfrom autoai_libs.transformers.exportable import CompressStrings\nfrom autoai_libs.transformers.exportable import NumpyReplaceMissingValues\nfrom autoai_libs.transformers.exportable import NumpyReplaceUnknownValues\nfrom autoai_libs.transformers.exportable import boolean2float\nfrom autoai_libs.transformers.exportable import CatImputer\nfrom autoai_libs.transformers.exportable import CatEncoder\nimport numpy as np\nfrom autoai_libs.transformers.exportable import float32_transform\nfrom autoai_libs.cognito.transforms.transform_utils import TAM\nfrom sklearn.decomposition import PCA\nfrom autoai_libs.cognito.transforms.transform_utils import FS1\nfrom autoai_libs.cognito.transforms.transform_utils import TA1\nimport autoai_libs.utils.fc_methods\nfrom xgboost import XGBClassifier\nfrom sklearn.pipeline import make_pipeline"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Pre-processing & Estimator."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "numpy_column_selector = NumpyColumnSelector(\n    columns=[0, 1, 2, 3, 4, 5, 6, 7, 8]\n)\ncompress_strings = CompressStrings(\n    compress_type=\"hash\",\n    dtypes_list=[\n        \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\", \"int_num\",\n        \"int_num\", \"int_num\", \"int_num\",\n    ],\n    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n    misslist_list=[[], [], [], [], [], [], [], [], []],\n)\nnumpy_replace_missing_values = NumpyReplaceMissingValues(\n    missing_values=[], filling_values=float(\"nan\")\n)\nnumpy_replace_unknown_values = NumpyReplaceUnknownValues(\n    filling_values=float(\"nan\"),\n    filling_values_list=[\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n        float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\"),\n    ],\n    missing_values_reference_list=[\"\", \"-\", \"?\", float(\"nan\")],\n)\ncat_imputer = CatImputer(\n    strategy=\"most_frequent\",\n    missing_values=float(\"nan\"),\n    sklearn_version_family=\"23\",\n)\ncat_encoder = CatEncoder(\n    encoding=\"ordinal\",\n    categories=\"auto\",\n    dtype=np.float64,\n    handle_unknown=\"error\",\n    sklearn_version_family=\"23\",\n)\ntam = TAM(\n    tans_class=PCA(),\n    name=\"pca\",\n    col_names=[\n        \"elecConsumption1\", \"waterConsumption1\", \"gasConsumption1\",\n        \"elecConsumption2\", \"waterConsumption2\", \"gasConsumption2\",\n        \"elecConsumption3\", \"waterConsumption3\", \"gasConsumption3\",\n    ],\n    col_dtypes=[\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n    ],\n)\nfs1_0 = FS1(\n    cols_ids_must_keep=range(0, 9),\n    additional_col_count_to_keep=8,\n    ptype=\"classification\",\n)\nta1 = TA1(\n    fun=np.sqrt,\n    name=\"sqrt\",\n    datatypes=[\"numeric\"],\n    feat_constraints=[\n        autoai_libs.utils.fc_methods.is_non_negative,\n        autoai_libs.utils.fc_methods.is_not_categorical,\n    ],\n    col_names=[\n        \"elecConsumption1\", \"waterConsumption1\", \"gasConsumption1\",\n        \"elecConsumption2\", \"waterConsumption2\", \"gasConsumption2\",\n        \"elecConsumption3\", \"waterConsumption3\", \"gasConsumption3\", \"pca_0\",\n        \"pca_1\", \"pca_2\", \"pca_3\", \"pca_5\", \"pca_6\", \"pca_7\", \"pca_8\",\n    ],\n    col_dtypes=[\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n        np.dtype(\"float32\"), np.dtype(\"float32\"), np.dtype(\"float32\"),\n        np.dtype(\"float32\"), np.dtype(\"float32\"),\n    ],\n)\nfs1_1 = FS1(\n    cols_ids_must_keep=range(0, 9),\n    additional_col_count_to_keep=8,\n    ptype=\"classification\",\n)\nxgb_classifier = XGBClassifier(\n    base_score=0.5,\n    booster=\"gbtree\",\n    colsample_bylevel=1,\n    colsample_bynode=1,\n    colsample_bytree=1,\n    gamma=0,\n    gpu_id=-1,\n    interaction_constraints=\"\",\n    learning_rate=0.300000012,\n    max_delta_step=0,\n    max_depth=3,\n    min_child_weight=1,\n    missing=float(\"nan\"),\n    monotone_constraints=\"()\",\n    num_parallel_tree=1,\n    random_state=33,\n    reg_alpha=0,\n    reg_lambda=1,\n    scale_pos_weight=1,\n    subsample=1,\n    tree_method=\"hist\",\n    validate_parameters=1,\n    verbosity=0,\n    nthread=1,\n    silent=True,\n    seed=33,\n)\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### Pipeline."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "pipeline = make_pipeline(\n    numpy_column_selector,\n    compress_strings,\n    numpy_replace_missing_values,\n    numpy_replace_unknown_values,\n    boolean2float(),\n    cat_imputer,\n    cat_encoder,\n    float32_transform(),\n    tam,\n    fs1_0,\n    ta1,\n    fs1_1,\n    xgb_classifier,\n)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"train\"></a>\n## Train pipeline model\n"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": "### Define scorer from the optimization metric\nThis cell constructs the cell scorer based on the experiment metadata."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "from sklearn.metrics import get_scorer\n\nscorer = get_scorer(experiment_metadata['scoring'])"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": "<a id=\"test_model\"></a>\n### Fit pipeline model\nIn this cell, the pipeline is fitted."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:01:19.291734Z",
                    "iopub.status.busy": "2020-10-12T14:01:19.244735Z",
                    "iopub.status.idle": "2020-10-12T14:01:19.338461Z",
                    "shell.execute_reply": "2020-10-12T14:01:19.338958Z"
                },
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                },
                "scrolled": true
            },
            "outputs": [],
            "source": "pipeline.fit(train_X.values, train_y.values);"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "<a id=\"test_model\"></a>\n## Test pipeline model"
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "pycharm": {
                    "name": "#%% md\n"
                }
            },
            "source": "Score the fitted pipeline with the generated scorer using the holdout dataset."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "execution": {
                    "iopub.execute_input": "2020-10-12T14:02:03.910267Z",
                    "iopub.status.busy": "2020-10-12T14:02:03.909710Z",
                    "iopub.status.idle": "2020-10-12T14:02:03.914154Z",
                    "shell.execute_reply": "2020-10-12T14:02:03.914727Z"
                },
                "pycharm": {
                    "is_executing": true,
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "score = scorer(pipeline, test_X.values, test_y.values)\nprint(score)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "pycharm": {
                    "name": "#%%\n"
                }
            },
            "outputs": [],
            "source": "pipeline.predict(test_X.values)"
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.10"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}